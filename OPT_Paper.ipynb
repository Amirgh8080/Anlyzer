{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "2Mgc7OvIOhHX"
      ],
      "authorship_tag": "ABX9TyNtzuWbXRG//2udTj9JtFWu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amirgh8080/Anlyzer/blob/main/OPT_Paper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Configuration"
      ],
      "metadata": {
        "id": "2Mgc7OvIOhHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install optuna\n",
        "! pip install botorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i849uQRWOlK6",
        "outputId": "bc205d30-c311-4a6f-e033-c08a0c83c7ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.2.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.14.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.37)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (1.3.8)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Collecting botorch\n",
            "  Downloading botorch-0.13.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from botorch) (4.12.2)\n",
            "Collecting pyre_extensions (from botorch)\n",
            "  Downloading pyre_extensions-0.0.32-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting gpytorch==1.14 (from botorch)\n",
            "  Downloading gpytorch-1.14-py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting linear_operator==0.6 (from botorch)\n",
            "  Downloading linear_operator-0.6-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: torch>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from botorch) (2.5.1+cu124)\n",
            "Collecting pyro-ppl>=1.8.4 (from botorch)\n",
            "  Downloading pyro_ppl-1.9.1-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from botorch) (1.13.1)\n",
            "Requirement already satisfied: multipledispatch in /usr/local/lib/python3.11/dist-packages (from botorch) (1.0.0)\n",
            "Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.11/dist-packages (from botorch) (3.5.0)\n",
            "Collecting jaxtyping (from gpytorch==1.14->botorch)\n",
            "  Downloading jaxtyping-0.2.37-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: mpmath<=1.3,>=0.19 in /usr/local/lib/python3.11/dist-packages (from gpytorch==1.14->botorch) (1.3.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from gpytorch==1.14->botorch) (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.11/dist-packages (from pyro-ppl>=1.8.4->botorch) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from pyro-ppl>=1.8.4->botorch) (3.4.0)\n",
            "Collecting pyro-api>=0.1.1 (from pyro-ppl>=1.8.4->botorch)\n",
            "  Downloading pyro_api-0.1.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.11/dist-packages (from pyro-ppl>=1.8.4->botorch) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.1->botorch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.1->botorch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.1->botorch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.1->botorch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.1->botorch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.1->botorch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.1->botorch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.1->botorch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.1->botorch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.1->botorch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (1.13.1)\n",
            "Collecting typing-inspect (from pyre_extensions->botorch)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting wadler-lindig>=0.1.3 (from jaxtyping->gpytorch==1.14->botorch)\n",
            "  Downloading wadler_lindig-0.1.3-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.1->botorch) (3.0.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->gpytorch==1.14->botorch) (1.4.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect->pyre_extensions->botorch)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading botorch-0.13.0-py3-none-any.whl (706 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 kB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gpytorch-1.14-py3-none-any.whl (277 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m277.7/277.7 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading linear_operator-0.6-py3-none-any.whl (176 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.3/176.3 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyro_ppl-1.9.1-py3-none-any.whl (755 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m110.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyre_extensions-0.0.32-py3-none-any.whl (12 kB)\n",
            "Downloading pyro_api-0.1.2-py3-none-any.whl (11 kB)\n",
            "Downloading jaxtyping-0.2.37-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading wadler_lindig-0.1.3-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: pyro-api, wadler-lindig, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mypy-extensions, typing-inspect, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jaxtyping, pyre_extensions, nvidia-cusolver-cu12, pyro-ppl, linear_operator, gpytorch, botorch\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed botorch-0.13.0 gpytorch-1.14 jaxtyping-0.2.37 linear_operator-0.6 mypy-extensions-1.0.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pyre_extensions-0.0.32 pyro-api-0.1.2 pyro-ppl-1.9.1 typing-inspect-0.9.0 wadler-lindig-0.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# First Implementation"
      ],
      "metadata": {
        "id": "sJ9ckFj5OpwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.autograd as autograd\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import optuna\n",
        "\n",
        "# Device Configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Generator\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim, img_shape):\n",
        "        super(Generator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(128, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(256, np.prod(img_shape)),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "        self.img_shape = img_shape\n",
        "\n",
        "    def forward(self, z):\n",
        "        img = self.model(z)\n",
        "        img = img.view(img.size(0), *self.img_shape)\n",
        "        return img\n",
        "\n",
        "# Discriminator with Mixup Regularization\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, img_shape):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(np.prod(img_shape), 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(128, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        img_flat = img.view(img.size(0), -1)\n",
        "        validity = self.model(img_flat)\n",
        "        return validity\n",
        "\n",
        "# Encoder for Feature Matching Loss\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, img_shape, latent_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(np.prod(img_shape), 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(128, latent_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        img_flat = img.view(img.size(0), -1)\n",
        "        latent_vector = self.model(img_flat)\n",
        "        return latent_vector\n",
        "\n",
        "# Gradient Penalty\n",
        "def compute_gradient_penalty(D, real_samples, fake_samples):\n",
        "    alpha = torch.rand(real_samples.size(0), 1, 1, 1, device=real_samples.device)\n",
        "    interpolates = (alpha * real_samples + (1 - alpha) * fake_samples).requires_grad_(True)\n",
        "    d_interpolates = D(interpolates)\n",
        "    fake = torch.ones(d_interpolates.size(), device=real_samples.device)\n",
        "    gradients = autograd.grad(outputs=d_interpolates, inputs=interpolates,\n",
        "                              grad_outputs=fake, create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
        "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
        "    return gradient_penalty\n",
        "\n",
        "# Anomaly Score Calculation\n",
        "def compute_anomaly_score(x, generator, encoder, discriminator):\n",
        "    x_reconstructed = generator(encoder(x))\n",
        "    reconstruction_error = ((x - x_reconstructed) ** 2).mean()\n",
        "    discriminator_error = ((discriminator(x) - discriminator(x_reconstructed)) ** 2).mean()\n",
        "    return reconstruction_error + discriminator_error\n",
        "\n",
        "# Dataset and DataLoader\n",
        "def get_dataloader(batch_size=32):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5], [0.5])\n",
        "    ])\n",
        "    dataset = datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True)\n",
        "    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Training Setup\n",
        "def train_wgangp(generator, discriminator, encoder, dataloader, latent_dim, epochs, lambda_gp=10, lr=0.0002):\n",
        "    optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.9))\n",
        "    optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.9))\n",
        "    optimizer_E = optim.Adam(encoder.parameters(), lr=lr, betas=(0.5, 0.9))\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for i, (imgs, _) in enumerate(dataloader):\n",
        "            real_imgs = imgs.to(device)\n",
        "            z = torch.randn(imgs.shape[0], latent_dim, device=device)\n",
        "            fake_imgs = generator(z)\n",
        "\n",
        "            optimizer_D.zero_grad()\n",
        "            real_validity = discriminator(real_imgs)\n",
        "            fake_validity = discriminator(fake_imgs.detach())\n",
        "            gradient_penalty = compute_gradient_penalty(discriminator, real_imgs, fake_imgs)\n",
        "            d_loss = fake_validity.mean() - real_validity.mean() + lambda_gp * gradient_penalty\n",
        "            d_loss.backward(retain_graph=True)\n",
        "            optimizer_D.step()\n",
        "\n",
        "            if i % 5 == 0:\n",
        "                optimizer_G.zero_grad()\n",
        "                g_loss = -discriminator(fake_imgs).mean()\n",
        "                g_loss.backward()\n",
        "                optimizer_G.step()\n",
        "        print(f\"Epoch {epoch}/{epochs} | D Loss: {d_loss.item()} | G Loss: {g_loss.item()}\")\n",
        "\n",
        "# Running Training\n",
        "generator = Generator(100, (1, 28, 28)).to(device)\n",
        "discriminator = Discriminator((1, 28, 28)).to(device)\n",
        "encoder = Encoder((1, 28, 28), 100).to(device)\n",
        "dataloader = get_dataloader(batch_size=32)\n",
        "train_wgangp(generator, discriminator, encoder, dataloader, latent_dim=100, epochs=5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkI86g_rOJrV",
        "outputId": "bc667c07-d505-4dd9-cac4-833ab1974a60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/5 | D Loss: -47.589019775390625 | G Loss: -367.225341796875\n",
            "Epoch 1/5 | D Loss: -94.1392593383789 | G Loss: -275.6246337890625\n",
            "Epoch 2/5 | D Loss: -218.41970825195312 | G Loss: -278.0072021484375\n",
            "Epoch 3/5 | D Loss: -175.2352752685547 | G Loss: -386.7821960449219\n",
            "Epoch 4/5 | D Loss: -271.40692138671875 | G Loss: -360.72027587890625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "940G9JCUkfZk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "dcd94a5b-03c9-413b-b612-555a80a21241"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "incomplete input (<ipython-input-7-d3b0ee59a206>, line 46)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-d3b0ee59a206>\"\u001b[0;36m, line \u001b[0;32m46\u001b[0m\n\u001b[0;31m    nn.ConvTranspose2d(feature_maps * 8, feature_maps *\u001b[0m\n\u001b[0m                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "from torchvision import transforms, datasets\n",
        "import torchvision.utils as vutils\n",
        "import optuna\n",
        "from optuna.samplers import TPESampler\n",
        "from optuna.integration import BoTorchSampler  # Replacing SkoptSampler\n",
        "from sklearn.metrics import roc_auc_score, precision_score, f1_score\n",
        "\n",
        "# Ensure BoTorch is installed\n",
        "try:\n",
        "    import botorch\n",
        "except ImportError:\n",
        "    print(\"BoTorch not found. Install it using: pip install botorch\")\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "#############################################\n",
        "# 1. Model Definitions\n",
        "#############################################\n",
        "\n",
        "class View(nn.Module):\n",
        "    \"\"\"Helper module to reshape tensors.\"\"\"\n",
        "    def __init__(self, *shape):\n",
        "        super(View, self).__init__()\n",
        "        self.shape = shape\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x.view(*self.shape)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim=100, feature_maps=64, channels=1):\n",
        "        super(Generator, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(latent_dim, feature_maps * 8 * 4 * 4),\n",
        "            nn.BatchNorm1d(feature_maps * 8 * 4 * 4),\n",
        "            nn.ReLU(True),\n",
        "            View(-1, feature_maps * 8, 4, 4),\n",
        "            nn.ConvTranspose2d(feature_maps * 8, feature_maps * 4, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(feature_maps * 4),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(feature_maps * 4, feature_maps * 2, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(feature_maps * 2),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(feature_maps * 2, feature_maps, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(feature_maps),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(feature_maps, channels, kernel_size=4, stride=2, padding=1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.net(z)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, feature_maps=64, channels=1):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(channels, feature_maps, kernel_size=4, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(feature_maps, feature_maps * 2, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(feature_maps * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(feature_maps * 2, feature_maps * 4, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(feature_maps * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(feature_maps * 4, feature_maps * 8, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(feature_maps * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(feature_maps * 8, 1, kernel_size=4, stride=1, padding=0)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.net(x)\n",
        "        return out.view(x.size(0), -1)\n",
        "\n",
        "#############################################\n",
        "# 2. Hyperparameter Optimization with Optuna\n",
        "#############################################\n",
        "\n",
        "def objective(trial, data_dir, sampler_type=\"TPE\"):\n",
        "    \"\"\"Optuna objective function for hyperparameter optimization.\"\"\"\n",
        "    latent_dim = trial.suggest_int(\"latent_dim\", 64, 128)\n",
        "    lr_G = trial.suggest_loguniform(\"lr_G\", 1e-5, 1e-3)\n",
        "    lr_D = trial.suggest_loguniform(\"lr_D\", 1e-5, 1e-3)\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64])\n",
        "    feature_maps = trial.suggest_categorical(\"feature_maps\", [32, 64])\n",
        "\n",
        "    # Create models\n",
        "    generator = Generator(latent_dim=latent_dim, feature_maps=feature_maps).to(device)\n",
        "    discriminator = Discriminator(feature_maps=feature_maps).to(device)\n",
        "\n",
        "    # Create dummy training data\n",
        "    train_loader = DataLoader(torch.randn(1000, 1, 64, 64), batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # Train GAN (replace this with actual training logic)\n",
        "    for epoch in range(3):  # Reduce epochs for quick testing\n",
        "        for real_imgs in train_loader:\n",
        "            real_imgs = real_imgs.to(device)\n",
        "            z = torch.randn(batch_size, latent_dim, device=device)\n",
        "            fake_imgs = generator(z)\n",
        "\n",
        "            # Simplified loss calculations\n",
        "            loss_D = discriminator(fake_imgs).mean() - discriminator(real_imgs).mean()\n",
        "            loss_G = -discriminator(fake_imgs).mean()\n",
        "\n",
        "    return loss_G.item()  # Minimize Generator loss\n",
        "\n",
        "#############################################\n",
        "# 3. Main Experiment Runner\n",
        "#############################################\n",
        "\n",
        "def run_experiment(exp_mode, data_dir):\n",
        "    \"\"\"Runs one of three experiments: baseline, TPE, or BO optimization.\"\"\"\n",
        "    if exp_mode == 'baseline':\n",
        "        config = {\n",
        "            \"latent_dim\": 100,\n",
        "            \"lr_G\": 2e-4,\n",
        "            \"lr_D\": 2e-4,\n",
        "            \"batch_size\": 32,\n",
        "            \"feature_maps\": 64,\n",
        "        }\n",
        "    else:\n",
        "        if exp_mode == 'tpe':\n",
        "            sampler = TPESampler()\n",
        "        elif exp_mode == 'bo':\n",
        "            sampler = BoTorchSampler()  # Replacing SkoptSampler\n",
        "        else:\n",
        "            raise ValueError(\"Unknown experiment mode\")\n",
        "\n",
        "        study = optuna.create_study(direction=\"minimize\", sampler=sampler)\n",
        "        study.optimize(lambda trial: objective(trial, data_dir), n_trials=5)\n",
        "        best_params = study.best_trial.params\n",
        "        print(f\"Best parameters from {exp_mode.upper()}:\", best_params)\n",
        "        config = best_params\n",
        "\n",
        "    # Model creation using best hyperparameters\n",
        "    generator = Generator(latent_dim=config[\"latent_dim\"], feature_maps=config[\"feature_maps\"]).to(device)\n",
        "    discriminator = Discriminator(feature_maps=config[\"feature_maps\"]).to(device)\n",
        "\n",
        "    # Dummy dataset for testing\n",
        "    train_loader = DataLoader(torch.randn(1000, 1, 64, 64), batch_size=config[\"batch_size\"], shuffle=True)\n",
        "\n",
        "    # Simulated training\n",
        "    for epoch in range(3):\n",
        "        for real_imgs in train_loader:\n",
        "            real_imgs = real_imgs.to(device)\n",
        "            z = torch.randn(config[\"batch_size\"], config[\"latent_dim\"], device=device)\n",
        "            fake_imgs = generator(z)\n",
        "            loss_G = -discriminator(fake_imgs).mean()\n",
        "\n",
        "    print(f\"Experiment {exp_mode.upper()} complete. Final Generator loss: {loss_G.item():.4f}\")\n",
        "\n",
        "#############################################\n",
        "# 4. Main Execution\n",
        "#############################################\n",
        "data_directory = \"./data\"  # Adjust path if needed\n",
        "for mode in ['baseline', 'tpe', 'bo']:\n",
        "  print(\"\\n==============================\")\n",
        "  print(f\"Running experiment: {mode.upper()}\")\n",
        "  print(\"==============================\")\n",
        "  run_experiment(mode, data_directory)\n"
      ]
    }
  ]
}