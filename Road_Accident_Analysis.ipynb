{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "hgXf-Z6daQ9T",
        "7I8Ai9E1aWCc",
        "s5Q6tBwgaZ1V"
      ],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyOYdJ3QIjIeLqAKsUTUMWZv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amirgh8080/Anlyzer/blob/main/Road_Accident_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Nessassary Libraries"
      ],
      "metadata": {
        "id": "WPJnlV92aAwe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lHHDkv82Zwm_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading"
      ],
      "metadata": {
        "id": "_v55DQ-0aOgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: use kaggle api /content/kaggle.json to download the dataset :datasets/sobhanmoosavi/us-accidents\n",
        "\n",
        "!pip install kaggle\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp /content/kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets download -d sobhanmoosavi/us-accidents\n",
        "!unzip us-accidents.zip\n"
      ],
      "metadata": {
        "id": "I4DkbvjgaQVn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0c4780f-32e7-4c04-9857-4400e75aa3a1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.3.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.11/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kaggle) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kaggle) (3.10)\n",
            "cp: cannot stat '/content/kaggle.json': No such file or directory\n",
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n",
            "Dataset URL: https://www.kaggle.com/datasets/sobhanmoosavi/us-accidents\n",
            "License(s): CC-BY-NC-SA-4.0\n",
            "Downloading us-accidents.zip to /content\n",
            "100% 650M/653M [00:04<00:00, 174MB/s]\n",
            "100% 653M/653M [00:04<00:00, 147MB/s]\n",
            "Archive:  us-accidents.zip\n",
            "  inflating: US_Accidents_March23.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "df = pd.read_csv('/content/US_Accidents_March23.csv')\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "O0YAPtoSgOw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4Uhc3engLXo",
        "outputId": "fdb0c9c3-c857-40f5-bd3e-5b1d3a518734"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7728394 entries, 0 to 7728393\n",
            "Data columns (total 46 columns):\n",
            " #   Column                 Dtype  \n",
            "---  ------                 -----  \n",
            " 0   ID                     object \n",
            " 1   Source                 object \n",
            " 2   Severity               int64  \n",
            " 3   Start_Time             object \n",
            " 4   End_Time               object \n",
            " 5   Start_Lat              float64\n",
            " 6   Start_Lng              float64\n",
            " 7   End_Lat                float64\n",
            " 8   End_Lng                float64\n",
            " 9   Distance(mi)           float64\n",
            " 10  Description            object \n",
            " 11  Street                 object \n",
            " 12  City                   object \n",
            " 13  County                 object \n",
            " 14  State                  object \n",
            " 15  Zipcode                object \n",
            " 16  Country                object \n",
            " 17  Timezone               object \n",
            " 18  Airport_Code           object \n",
            " 19  Weather_Timestamp      object \n",
            " 20  Temperature(F)         float64\n",
            " 21  Wind_Chill(F)          float64\n",
            " 22  Humidity(%)            float64\n",
            " 23  Pressure(in)           float64\n",
            " 24  Visibility(mi)         float64\n",
            " 25  Wind_Direction         object \n",
            " 26  Wind_Speed(mph)        float64\n",
            " 27  Precipitation(in)      float64\n",
            " 28  Weather_Condition      object \n",
            " 29  Amenity                bool   \n",
            " 30  Bump                   bool   \n",
            " 31  Crossing               bool   \n",
            " 32  Give_Way               bool   \n",
            " 33  Junction               bool   \n",
            " 34  No_Exit                bool   \n",
            " 35  Railway                bool   \n",
            " 36  Roundabout             bool   \n",
            " 37  Station                bool   \n",
            " 38  Stop                   bool   \n",
            " 39  Traffic_Calming        bool   \n",
            " 40  Traffic_Signal         bool   \n",
            " 41  Turning_Loop           bool   \n",
            " 42  Sunrise_Sunset         object \n",
            " 43  Civil_Twilight         object \n",
            " 44  Nautical_Twilight      object \n",
            " 45  Astronomical_Twilight  object \n",
            "dtypes: bool(13), float64(12), int64(1), object(20)\n",
            "memory usage: 2.0+ GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "id": "-KMQa74EgPQI",
        "outputId": "f23a819c-9f96-409e-eb11-1b49a5786184"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.describe of                 ID   Source  Severity           Start_Time  \\\n",
              "0              A-1  Source2         3  2016-02-08 05:46:00   \n",
              "1              A-2  Source2         2  2016-02-08 06:07:59   \n",
              "2              A-3  Source2         2  2016-02-08 06:49:27   \n",
              "3              A-4  Source2         3  2016-02-08 07:23:34   \n",
              "4              A-5  Source2         2  2016-02-08 07:39:07   \n",
              "...            ...      ...       ...                  ...   \n",
              "7728389  A-7777757  Source1         2  2019-08-23 18:03:25   \n",
              "7728390  A-7777758  Source1         2  2019-08-23 19:11:30   \n",
              "7728391  A-7777759  Source1         2  2019-08-23 19:00:21   \n",
              "7728392  A-7777760  Source1         2  2019-08-23 19:00:21   \n",
              "7728393  A-7777761  Source1         2  2019-08-23 18:52:06   \n",
              "\n",
              "                    End_Time  Start_Lat   Start_Lng   End_Lat    End_Lng  \\\n",
              "0        2016-02-08 11:00:00  39.865147  -84.058723       NaN        NaN   \n",
              "1        2016-02-08 06:37:59  39.928059  -82.831184       NaN        NaN   \n",
              "2        2016-02-08 07:19:27  39.063148  -84.032608       NaN        NaN   \n",
              "3        2016-02-08 07:53:34  39.747753  -84.205582       NaN        NaN   \n",
              "4        2016-02-08 08:09:07  39.627781  -84.188354       NaN        NaN   \n",
              "...                      ...        ...         ...       ...        ...   \n",
              "7728389  2019-08-23 18:32:01  34.002480 -117.379360  33.99888 -117.37094   \n",
              "7728390  2019-08-23 19:38:23  32.766960 -117.148060  32.76555 -117.15363   \n",
              "7728391  2019-08-23 19:28:49  33.775450 -117.847790  33.77740 -117.85727   \n",
              "7728392  2019-08-23 19:29:42  33.992460 -118.403020  33.98311 -118.39565   \n",
              "7728393  2019-08-23 19:21:31  34.133930 -117.230920  34.13736 -117.23934   \n",
              "\n",
              "         Distance(mi)  ... Roundabout Station   Stop Traffic_Calming  \\\n",
              "0               0.010  ...      False   False  False           False   \n",
              "1               0.010  ...      False   False  False           False   \n",
              "2               0.010  ...      False   False  False           False   \n",
              "3               0.010  ...      False   False  False           False   \n",
              "4               0.010  ...      False   False  False           False   \n",
              "...               ...  ...        ...     ...    ...             ...   \n",
              "7728389         0.543  ...      False   False  False           False   \n",
              "7728390         0.338  ...      False   False  False           False   \n",
              "7728391         0.561  ...      False   False  False           False   \n",
              "7728392         0.772  ...      False   False  False           False   \n",
              "7728393         0.537  ...      False   False  False           False   \n",
              "\n",
              "        Traffic_Signal Turning_Loop Sunrise_Sunset Civil_Twilight  \\\n",
              "0                False        False          Night          Night   \n",
              "1                False        False          Night          Night   \n",
              "2                 True        False          Night          Night   \n",
              "3                False        False          Night            Day   \n",
              "4                 True        False            Day            Day   \n",
              "...                ...          ...            ...            ...   \n",
              "7728389          False        False            Day            Day   \n",
              "7728390          False        False            Day            Day   \n",
              "7728391          False        False            Day            Day   \n",
              "7728392          False        False            Day            Day   \n",
              "7728393          False        False            Day            Day   \n",
              "\n",
              "        Nautical_Twilight Astronomical_Twilight  \n",
              "0                   Night                 Night  \n",
              "1                   Night                   Day  \n",
              "2                     Day                   Day  \n",
              "3                     Day                   Day  \n",
              "4                     Day                   Day  \n",
              "...                   ...                   ...  \n",
              "7728389               Day                   Day  \n",
              "7728390               Day                   Day  \n",
              "7728391               Day                   Day  \n",
              "7728392               Day                   Day  \n",
              "7728393               Day                   Day  \n",
              "\n",
              "[7728394 rows x 46 columns]>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pandas.core.generic.NDFrame.describe</b><br/>def describe(percentiles=None, include=None, exclude=None) -&gt; Self</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py</a>Generate descriptive statistics.\n",
              "\n",
              "Descriptive statistics include those that summarize the central\n",
              "tendency, dispersion and shape of a\n",
              "dataset&#x27;s distribution, excluding ``NaN`` values.\n",
              "\n",
              "Analyzes both numeric and object series, as well\n",
              "as ``DataFrame`` column sets of mixed data types. The output\n",
              "will vary depending on what is provided. Refer to the notes\n",
              "below for more detail.\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "percentiles : list-like of numbers, optional\n",
              "    The percentiles to include in the output. All should\n",
              "    fall between 0 and 1. The default is\n",
              "    ``[.25, .5, .75]``, which returns the 25th, 50th, and\n",
              "    75th percentiles.\n",
              "include : &#x27;all&#x27;, list-like of dtypes or None (default), optional\n",
              "    A white list of data types to include in the result. Ignored\n",
              "    for ``Series``. Here are the options:\n",
              "\n",
              "    - &#x27;all&#x27; : All columns of the input will be included in the output.\n",
              "    - A list-like of dtypes : Limits the results to the\n",
              "      provided data types.\n",
              "      To limit the result to numeric types submit\n",
              "      ``numpy.number``. To limit it instead to object columns submit\n",
              "      the ``numpy.object`` data type. Strings\n",
              "      can also be used in the style of\n",
              "      ``select_dtypes`` (e.g. ``df.describe(include=[&#x27;O&#x27;])``). To\n",
              "      select pandas categorical columns, use ``&#x27;category&#x27;``\n",
              "    - None (default) : The result will include all numeric columns.\n",
              "exclude : list-like of dtypes or None (default), optional,\n",
              "    A black list of data types to omit from the result. Ignored\n",
              "    for ``Series``. Here are the options:\n",
              "\n",
              "    - A list-like of dtypes : Excludes the provided data types\n",
              "      from the result. To exclude numeric types submit\n",
              "      ``numpy.number``. To exclude object columns submit the data\n",
              "      type ``numpy.object``. Strings can also be used in the style of\n",
              "      ``select_dtypes`` (e.g. ``df.describe(exclude=[&#x27;O&#x27;])``). To\n",
              "      exclude pandas categorical columns, use ``&#x27;category&#x27;``\n",
              "    - None (default) : The result will exclude nothing.\n",
              "\n",
              "Returns\n",
              "-------\n",
              "Series or DataFrame\n",
              "    Summary statistics of the Series or Dataframe provided.\n",
              "\n",
              "See Also\n",
              "--------\n",
              "DataFrame.count: Count number of non-NA/null observations.\n",
              "DataFrame.max: Maximum of the values in the object.\n",
              "DataFrame.min: Minimum of the values in the object.\n",
              "DataFrame.mean: Mean of the values.\n",
              "DataFrame.std: Standard deviation of the observations.\n",
              "DataFrame.select_dtypes: Subset of a DataFrame including/excluding\n",
              "    columns based on their dtype.\n",
              "\n",
              "Notes\n",
              "-----\n",
              "For numeric data, the result&#x27;s index will include ``count``,\n",
              "``mean``, ``std``, ``min``, ``max`` as well as lower, ``50`` and\n",
              "upper percentiles. By default the lower percentile is ``25`` and the\n",
              "upper percentile is ``75``. The ``50`` percentile is the\n",
              "same as the median.\n",
              "\n",
              "For object data (e.g. strings or timestamps), the result&#x27;s index\n",
              "will include ``count``, ``unique``, ``top``, and ``freq``. The ``top``\n",
              "is the most common value. The ``freq`` is the most common value&#x27;s\n",
              "frequency. Timestamps also include the ``first`` and ``last`` items.\n",
              "\n",
              "If multiple object values have the highest count, then the\n",
              "``count`` and ``top`` results will be arbitrarily chosen from\n",
              "among those with the highest count.\n",
              "\n",
              "For mixed data types provided via a ``DataFrame``, the default is to\n",
              "return only an analysis of numeric columns. If the dataframe consists\n",
              "only of object and categorical data without any numeric columns, the\n",
              "default is to return an analysis of both the object and categorical\n",
              "columns. If ``include=&#x27;all&#x27;`` is provided as an option, the result\n",
              "will include a union of attributes of each type.\n",
              "\n",
              "The `include` and `exclude` parameters can be used to limit\n",
              "which columns in a ``DataFrame`` are analyzed for the output.\n",
              "The parameters are ignored when analyzing a ``Series``.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "Describing a numeric ``Series``.\n",
              "\n",
              "&gt;&gt;&gt; s = pd.Series([1, 2, 3])\n",
              "&gt;&gt;&gt; s.describe()\n",
              "count    3.0\n",
              "mean     2.0\n",
              "std      1.0\n",
              "min      1.0\n",
              "25%      1.5\n",
              "50%      2.0\n",
              "75%      2.5\n",
              "max      3.0\n",
              "dtype: float64\n",
              "\n",
              "Describing a categorical ``Series``.\n",
              "\n",
              "&gt;&gt;&gt; s = pd.Series([&#x27;a&#x27;, &#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;])\n",
              "&gt;&gt;&gt; s.describe()\n",
              "count     4\n",
              "unique    3\n",
              "top       a\n",
              "freq      2\n",
              "dtype: object\n",
              "\n",
              "Describing a timestamp ``Series``.\n",
              "\n",
              "&gt;&gt;&gt; s = pd.Series([\n",
              "...     np.datetime64(&quot;2000-01-01&quot;),\n",
              "...     np.datetime64(&quot;2010-01-01&quot;),\n",
              "...     np.datetime64(&quot;2010-01-01&quot;)\n",
              "... ])\n",
              "&gt;&gt;&gt; s.describe()\n",
              "count                      3\n",
              "mean     2006-09-01 08:00:00\n",
              "min      2000-01-01 00:00:00\n",
              "25%      2004-12-31 12:00:00\n",
              "50%      2010-01-01 00:00:00\n",
              "75%      2010-01-01 00:00:00\n",
              "max      2010-01-01 00:00:00\n",
              "dtype: object\n",
              "\n",
              "Describing a ``DataFrame``. By default only numeric fields\n",
              "are returned.\n",
              "\n",
              "&gt;&gt;&gt; df = pd.DataFrame({&#x27;categorical&#x27;: pd.Categorical([&#x27;d&#x27;, &#x27;e&#x27;, &#x27;f&#x27;]),\n",
              "...                    &#x27;numeric&#x27;: [1, 2, 3],\n",
              "...                    &#x27;object&#x27;: [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;]\n",
              "...                    })\n",
              "&gt;&gt;&gt; df.describe()\n",
              "       numeric\n",
              "count      3.0\n",
              "mean       2.0\n",
              "std        1.0\n",
              "min        1.0\n",
              "25%        1.5\n",
              "50%        2.0\n",
              "75%        2.5\n",
              "max        3.0\n",
              "\n",
              "Describing all columns of a ``DataFrame`` regardless of data type.\n",
              "\n",
              "&gt;&gt;&gt; df.describe(include=&#x27;all&#x27;)  # doctest: +SKIP\n",
              "       categorical  numeric object\n",
              "count            3      3.0      3\n",
              "unique           3      NaN      3\n",
              "top              f      NaN      a\n",
              "freq             1      NaN      1\n",
              "mean           NaN      2.0    NaN\n",
              "std            NaN      1.0    NaN\n",
              "min            NaN      1.0    NaN\n",
              "25%            NaN      1.5    NaN\n",
              "50%            NaN      2.0    NaN\n",
              "75%            NaN      2.5    NaN\n",
              "max            NaN      3.0    NaN\n",
              "\n",
              "Describing a column from a ``DataFrame`` by accessing it as\n",
              "an attribute.\n",
              "\n",
              "&gt;&gt;&gt; df.numeric.describe()\n",
              "count    3.0\n",
              "mean     2.0\n",
              "std      1.0\n",
              "min      1.0\n",
              "25%      1.5\n",
              "50%      2.0\n",
              "75%      2.5\n",
              "max      3.0\n",
              "Name: numeric, dtype: float64\n",
              "\n",
              "Including only numeric columns in a ``DataFrame`` description.\n",
              "\n",
              "&gt;&gt;&gt; df.describe(include=[np.number])\n",
              "       numeric\n",
              "count      3.0\n",
              "mean       2.0\n",
              "std        1.0\n",
              "min        1.0\n",
              "25%        1.5\n",
              "50%        2.0\n",
              "75%        2.5\n",
              "max        3.0\n",
              "\n",
              "Including only string columns in a ``DataFrame`` description.\n",
              "\n",
              "&gt;&gt;&gt; df.describe(include=[object])  # doctest: +SKIP\n",
              "       object\n",
              "count       3\n",
              "unique      3\n",
              "top         a\n",
              "freq        1\n",
              "\n",
              "Including only categorical columns from a ``DataFrame`` description.\n",
              "\n",
              "&gt;&gt;&gt; df.describe(include=[&#x27;category&#x27;])\n",
              "       categorical\n",
              "count            3\n",
              "unique           3\n",
              "top              d\n",
              "freq             1\n",
              "\n",
              "Excluding numeric columns from a ``DataFrame`` description.\n",
              "\n",
              "&gt;&gt;&gt; df.describe(exclude=[np.number])  # doctest: +SKIP\n",
              "       categorical object\n",
              "count            3      3\n",
              "unique           3      3\n",
              "top              f      a\n",
              "freq             1      1\n",
              "\n",
              "Excluding object columns from a ``DataFrame`` description.\n",
              "\n",
              "&gt;&gt;&gt; df.describe(exclude=[object])  # doctest: +SKIP\n",
              "       categorical  numeric\n",
              "count            3      3.0\n",
              "unique           3      NaN\n",
              "top              f      NaN\n",
              "freq             1      NaN\n",
              "mean           NaN      2.0\n",
              "std            NaN      1.0\n",
              "min            NaN      1.0\n",
              "25%            NaN      1.5\n",
              "50%            NaN      2.0\n",
              "75%            NaN      2.5\n",
              "max            NaN      3.0</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 11734);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Start_Time'] = pd.to_datetime(df['Start_Time'], format='mixed')\n",
        "\n",
        "# Aggregate accidents by date (daily counts)\n",
        "df['Date'] = df['Start_Time'].dt.date\n",
        "daily_accidents = df.groupby('Date').size().reset_index(name='Accident_Count')\n"
      ],
      "metadata": {
        "id": "3JAfS4vpg4ba"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: Plot the time series\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.plot(daily_accidents['Date'], daily_accidents['Accident_Count'], label='Daily Accident Count')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Accident Count')\n",
        "plt.title('Daily Accident Count Over Time')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "XpPdTmMjhojI",
        "outputId": "3d368aa9-20af-49a5-ec23-0f8d1b6c9095"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'plt' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-07d58e113dd5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Optional: Plot the time series\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdaily_accidents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdaily_accidents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Accident_Count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Daily Accident Count'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accident Count'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_lag_features(df, lag=7):\n",
        "    \"\"\"\n",
        "    Create lag features for a time series DataFrame.\n",
        "    Given a DataFrame with 'Accident_Count', this function creates lag_1, lag_2, ..., lag_{lag}\n",
        "    as features to forecast the current day's accident count.\n",
        "    \"\"\"\n",
        "    df_new = df.copy()\n",
        "    for i in range(1, lag+1):\n",
        "        df_new[f'lag_{i}'] = df_new['Accident_Count'].shift(i)\n",
        "    df_new = df_new.dropna().reset_index(drop=True)\n",
        "    return df_new"
      ],
      "metadata": {
        "id": "RJ287HQthwIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure the data is sorted by date\n",
        "daily_accidents['Date'] = pd.to_datetime(daily_accidents['Date'])\n",
        "daily_accidents = daily_accidents.sort_values('Date').reset_index(drop=True)"
      ],
      "metadata": {
        "id": "wS8Cx8oVhjsp"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest (RF)"
      ],
      "metadata": {
        "id": "7I8Ai9E1aWCc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_model = RandomForestRegressor(\n",
        "    n_estimators=100,  # Default hyperparameters (tune if needed)\n",
        "    random_state=42\n",
        ")\n",
        "rf_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "VG1BmHPCaYoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Support Vector Machine (SVM)"
      ],
      "metadata": {
        "id": "s5Q6tBwgaZ1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm_model = SVR(\n",
        "    kernel='rbf',  # RBF kernel for non-linear regression\n",
        "    C=1.0,         # Default hyperparameters (tune if needed)\n",
        "    epsilon=0.1\n",
        ")\n",
        "svm_model.fit(X_train_scaled, y_train)"
      ],
      "metadata": {
        "id": "dJJAsGgDacsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate Models"
      ],
      "metadata": {
        "id": "ys-uybwladkD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, X_train, X_test, y_train, y_test, is_svm=False):\n",
        "    # Predictions\n",
        "    if is_svm:\n",
        "        y_pred_train = model.predict(X_train)\n",
        "        y_pred_test = model.predict(X_test)\n",
        "    else:\n",
        "        y_pred_train = model.predict(X_train)\n",
        "        y_pred_test = model.predict(X_test)\n",
        "\n",
        "    # Metrics\n",
        "    metrics = {\n",
        "        'MAE_train': mean_absolute_error(y_train, y_pred_train),\n",
        "        'MSE_train': mean_squared_error(y_train, y_pred_train),\n",
        "        'RMSE_train': np.sqrt(mean_squared_error(y_train, y_pred_train)),\n",
        "        'R2_train': r2_score(y_train, y_pred_train),\n",
        "        'MAE_test': mean_absolute_error(y_test, y_pred_test),\n",
        "        'MSE_test': mean_squared_error(y_test, y_pred_test),\n",
        "        'RMSE_test': np.sqrt(mean_squared_error(y_test, y_pred_test)),\n",
        "        'R2_test': r2_score(y_test, y_pred_test)\n",
        "    }\n",
        "    return metrics\n",
        "\n",
        "# Evaluate RF\n",
        "rf_metrics = evaluate_model(rf_model, X_train, X_test, y_train, y_test)\n",
        "\n",
        "# Evaluate SVM\n",
        "svm_metrics = evaluate_model(svm_model, X_train_scaled, X_test_scaled, y_train, y_test, is_svm=True)\n",
        "\n",
        "# Print results\n",
        "print(\"Random Forest Metrics:\")\n",
        "print(pd.DataFrame([rf_metrics]))\n",
        "print(\"\\nSupport Vector Machine Metrics:\")\n",
        "print(pd.DataFrame([svm_metrics]))"
      ],
      "metadata": {
        "id": "V6tMDfl7af8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results Interpretation"
      ],
      "metadata": {
        "id": "ZLzaJwqNagbr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "69Q-XoQXaqxw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}